{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T22:25:03.835354600Z",
     "start_time": "2026-01-11T22:24:55.074980200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Unset SPARK_HOME to ensure the pyspark library uses its own bundled Spark runtime,\n",
    "# preventing conflicts with any globally installed Spark versions.\n",
    "# Please restart the Jupyter kernel for this change to take effect.\n",
    "os.environ.pop('SPARK_HOME', None)\n",
    "\n",
    "## DEFINE VARIABLES\n",
    "CATALOG_URI = \"http://nessie:19120/api/v2\"\n",
    "WAREHOUSE = \"s3://lakehouse/\"\n",
    "STORAGE_URI = \"http://minio:9000\"\n",
    "POSTGRES_JDBC_URL = \"jdbc:postgresql://postgres:5432/poc\"\n",
    "\n",
    "## CONFIGURE SPARK SESSION\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName('Iceberg Ingestion')\n",
    "    .set('spark.jars.packages',\n",
    "         'org.postgresql:postgresql:42.7.3,'\n",
    "         'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "         'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "         'software.amazon.awssdk:bundle:2.24.8,'\n",
    "         'software.amazon.awssdk:url-connection-client:2.24.8')\n",
    "    .set('spark.sql.extensions',\n",
    "         'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "         'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "    .set('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "    .set('spark.sql.catalog.iceberg.uri', CATALOG_URI)\n",
    "    .set('spark.sql.catalog.iceberg.ref', 'main')\n",
    "    .set('spark.sql.catalog.iceberg.authentication.type', 'NONE')\n",
    "    .set('spark.sql.catalog.iceberg.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "    .set('spark.sql.catalog.iceberg.warehouse', WAREHOUSE)\n",
    "    .set('spark.sql.catalog.iceberg.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "    .set('spark.sql.catalog.iceberg.client.region', 'us-east-1')\n",
    "    .set('spark.sql.catalog.iceberg.s3.endpoint', STORAGE_URI)\n",
    "    .set('spark.sql.catalog.iceberg.s3.access-key-id', 'admin')\n",
    "    .set('spark.sql.catalog.iceberg.s3.secret-access-key', 'PASSWORD')\n",
    "    .set('spark.sql.catalog.iceberg.s3.path-style-access', 'true')\n",
    "    .set(\"spark.hadoop.fs.s3a.endpoint\", STORAGE_URI)\n",
    "    .set(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .set(\"spark.hadoop.fs.s3a.secret.key\", \"PASSWORD\")\n",
    "    .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    ")\n",
    "\n",
    "## START SPARK SESSION\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark Running @ \" + datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M:%S\"))\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running @ 2026-01-11 17:25:03\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T22:25:13.507598900Z",
     "start_time": "2026-01-11T22:25:09.450246900Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Define the JDBC connection properties\n",
    "properties = {\n",
    "    \"user\": \"poc\",\n",
    "    \"password\": \"PASSWORD\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Read the sales_data table from Postgres into a Spark DataFrame\n",
    "transactions_df = spark.read.jdbc(url=POSTGRES_JDBC_URL, table=\"transactions\", properties=properties)\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "transactions_df.show()"
   ],
   "id": "adafbf47a9fb2e63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "|     id|transaction_date|transaction_type|posted_date|     description|amount|\n",
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "|txn_001|      2024-01-01|          credit| 2024-01-01| Initial Deposit|1000.0|\n",
      "|txn_002|      2024-01-02|           debit| 2024-01-03|     Coffee Shop|   4.5|\n",
      "|txn_003|      2024-01-05|           debit| 2024-01-06|Online Bookstore| 25.99|\n",
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T22:25:38.764663900Z",
     "start_time": "2026-01-11T22:25:35.202975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manipulate the data\n",
    "# Multiply each amount by 2\n",
    "transactions_df = transactions_df.withColumn(\"amount\", col(\"amount\") * 2)\n",
    "\n",
    "# Create a namespace\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS iceberg.poc;\")\n",
    "\n",
    "# Write the DataFrame to an Iceberg table in the Nessie catalog\n",
    "transactions_df.writeTo(\"iceberg.poc.transactions\").createOrReplace()\n",
    "\n",
    "# Verify that the data was written to Iceberg by reading the table\n",
    "spark.read.table(\"iceberg.poc.transactions\").show()"
   ],
   "id": "bbbee8c67336ea64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "|     id|transaction_date|transaction_type|posted_date|     description|amount|\n",
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "|txn_001|      2024-01-01|          credit| 2024-01-01| Initial Deposit|2000.0|\n",
      "|txn_002|      2024-01-02|           debit| 2024-01-03|     Coffee Shop|   9.0|\n",
      "|txn_003|      2024-01-05|           debit| 2024-01-06|Online Bookstore| 51.98|\n",
      "+-------+----------------+----------------+-----------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dbed9132405854b6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
